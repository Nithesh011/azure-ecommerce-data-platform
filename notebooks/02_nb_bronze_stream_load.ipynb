{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "CELL 1 â€” Event Hub + Schema Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-12-12T07:29:42.6372039Z",
              "execution_start_time": "2025-12-12T07:29:42.1113782Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "b50b6a13-10c1-4459-a167-fec6fe19a2f3",
              "queued_time": "2025-12-12T07:25:46.6790948Z",
              "session_id": "7",
              "session_start_time": "2025-12-12T07:25:46.6808015Z",
              "spark_jobs": null,
              "spark_pool": "spkecommerce",
              "state": "finished",
              "statement_id": 2,
              "statement_ids": [
                2
              ]
            },
            "text/plain": [
              "StatementMeta(spkecommerce, 7, 2, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Event Hub connection\n",
        "# Use the CONSUMER POLICY (Listen) created at the EVENT HUB level\n",
        "CONSUMER_CONN = \"your-consumer-policy-primary-connection-string\"\n",
        "\n",
        "# Encrypt the connection string for Spark\n",
        "ehConf = {\n",
        "    \"eventhubs.connectionString\": sc._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(CONSUMER_CONN)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "ðŸ§ª CELL 2 â€” Define Schema and Read Stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-12-12T07:33:26.3467161Z",
              "execution_start_time": "2025-12-12T07:33:24.2976535Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "07f0a9dc-4da2-4190-bbe5-1e7ab0238e5c",
              "queued_time": "2025-12-12T07:33:24.2957779Z",
              "session_id": "7",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "spkecommerce",
              "state": "finished",
              "statement_id": 4,
              "statement_ids": [
                4
              ]
            },
            "text/plain": [
              "StatementMeta(spkecommerce, 7, 4, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pyspark.sql.functions import from_json, col, explode, current_timestamp\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType\n",
        "\n",
        "# Schema of FakeStore cart events\n",
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType()),\n",
        "    StructField(\"userId\", IntegerType()),\n",
        "    StructField(\"date\", StringType()),\n",
        "    StructField(\"products\", ArrayType(\n",
        "        StructType([\n",
        "            StructField(\"productId\", IntegerType()),\n",
        "            StructField(\"quantity\", IntegerType())\n",
        "        ])\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Step 1: Read event hub stream\n",
        "df_eh = spark.readStream \\\n",
        "    .format(\"eventhubs\") \\\n",
        "    .options(**ehConf) \\\n",
        "    .load()\n",
        "\n",
        "# Step 2: Convert binary body â†’ text JSON string\n",
        "df_string = df_eh.selectExpr(\"CAST(body AS STRING) as json_str\")\n",
        "\n",
        "# Step 3: Parse JSON\n",
        "df_parsed = df_string.select(from_json(col(\"json_str\"), schema).alias(\"data\")).select(\"data.*\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "ðŸ§ª CELL 3 â€” Flatten and Add Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-12-12T07:33:31.8420969Z",
              "execution_start_time": "2025-12-12T07:33:31.5447024Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "3abe2932-2568-4894-85ce-9b5a5256d278",
              "queued_time": "2025-12-12T07:33:31.5429527Z",
              "session_id": "7",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "spkecommerce",
              "state": "finished",
              "statement_id": 6,
              "statement_ids": [
                6
              ]
            },
            "text/plain": [
              "StatementMeta(spkecommerce, 7, 6, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Flatten the nested products array\n",
        "df_flat = df_parsed.withColumn(\"product\", explode(col(\"products\"))) \\\n",
        "    .select(\n",
        "        col(\"id\").alias(\"cart_id\"),\n",
        "        col(\"userId\").alias(\"user_id\"),\n",
        "        col(\"date\").alias(\"cart_date\"),\n",
        "        col(\"product.productId\").alias(\"product_id\"),\n",
        "        col(\"product.quantity\").alias(\"quantity\"),\n",
        "        current_timestamp().alias(\"ingest_ts\")\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "ðŸ§ª CELL 4 â€” Write to Bronze Streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-12-12T07:33:54.3435744Z",
              "execution_start_time": "2025-12-12T07:33:52.2988125Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "311f2a2c-ff16-483b-b825-6a2d123f22fb",
              "queued_time": "2025-12-12T07:33:52.2969168Z",
              "session_id": "7",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "spkecommerce",
              "state": "finished",
              "statement_id": 7,
              "statement_ids": [
                7
              ]
            },
            "text/plain": [
              "StatementMeta(spkecommerce, 7, 7, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Streaming consumer started.\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "bronze_path = \"abfss://datalake@stecomdata123.dfs.core.windows.net/bronze/fakestore/stream/\"\n",
        "checkpoint_path = \"abfss://datalake@stecomdata123.dfs.core.windows.net/bronze/fakestore/checkpoints/stream/\"\n",
        "\n",
        "# Start structured stream\n",
        "query = df_flat.writeStream \\\n",
        "    .format(\"parquet\") \\\n",
        "    .option(\"path\", bronze_path) \\\n",
        "    .option(\"checkpointLocation\", checkpoint_path) \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .trigger(processingTime=\"30 seconds\") \\\n",
        "    .start()\n",
        "\n",
        "print(\"Streaming consumer started.\")\n",
        "\n",
        "# View last batch details:\n",
        "# query.lastProgress\n"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
